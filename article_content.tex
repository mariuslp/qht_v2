\section{Introduction}
\subsection{Motivation}

Throughout this paper, we are interested in the following problem: 
\begin{definition}[Duplicate detection problem over a sliding window, wDDP] Given a stream $E_n = (e_1, e_2, \dotsc, e_n)$, a sliding window size $w$ and a \enquote{new} item $e^\star$, find whether $e^\star$ is also present in the last $w$ elements of the stream, ie., whether $e^\star \in \{e_{n-w+1}, \dotsc, e_n\}$.
At every time increment, the new item is added to the stream, i.e., $E_{n+1} = E_n \mid e^\star$ where $\mid$ denotes concatenation. 
\end{definition}

Note that for $w = \infty$, the problem becomes finding whether an element is a duplicate amongst all previous stream elements. For simplicity in the notation, when we refer to $\infty$DDP we instead write DDP.

Instances of the wDDP abound in computer science, with applications to file system indexation, database queries, network load balancing, network management \cite{10.5555/647912.740658}, in credit card fraud detection \cite{DBLP:journals/corr/abs-1709-08920}, phone calls data mining \cite{10.1145/347090.347094}, etc. A discussion about algorithms on large data streams can be found in \cite{10.1145/776985.776986}. 

In practice, additional constraints exist that we can capture with the following definition:
\begin{definition}[wDDP with bounded memory]
	At every time step $n$, given $e^{\star}$ and a current state (dependent on history) of at most $M$ bits, solve the wDDP for $E_n$ and $e^{\star}$.
\end{definition}
%Even when the stream is bounded, i.e. $\lim_{n\to\infty}|E_n| < \infty$, it may be impractical to perform a complete lookup and approximate solutions are desirable. 
%Perfect detection of duplicates in a stream with $U$ possible values requires $U$ bits of memory \cite[Theorem 2.1]{10.1145/3297280.3297335}: even for modest situations (e.g. 64-bit nonces, corresponding to $2^{64}$ possible values) this is quickly impractical. As a result, we need a further relaxation of the DDP that allows for errors: 
Perfect detection is however not always reachable and it might be more practical to work on a further relaxation of the problem, allowing for errors.

%\begin{definition}[Approximate wDDP with bounded memory]
%	Solve the wDDP using at most $M$ bits of memory, with at most $\epsilon < 1/2$ mispredictions.\footnote{Given a classifier with $\epsilon > 1/2$, we obtain a classifier with $\epsilon < 1/2$ by reversing its output.} 
%\end{definition}

Approximate duplicate detection has many real-life use cases, and can sometimes play a critical role, for instance in cryptographic schemes where all security and secrecy fall apart as soon as a random nonce is used twice, such as the ElGamal \cite{10.1007/3-540-39568-7_2} or ECDSA signatures. Other uses include improvements over caches \cite{4484874}, duplicate clicks \cite{10.1145/1060745.1060753}, and others.

On a side note, it is clear that the input distribution plays a central role regarding how efficiently the wDDP can be solved. For instance, some deterministic streams may be expressed very compactly (such as the output of a PRNG with known seed) making the wDDP relatively easy. Information-theoretically, if the source has $U$ bits of entropy then the situation is equivalent to having an $U$-bit, uniformly distributed input. This is the setting we consider here.

As said before, when the window size in wDDP grows infinitely large, it becomes the following problem: find whether $e^\star \in E_n$. %This \enquote{non-windowed} problem predates in fact the definition of wDDP, and several algorithms have been proposed for this problem: \cite{Den06,10.1145/3297280.3297335,Dut13} and a slight variation of Cuckoo Filters \cite{Fan14} suggested by \cite{10.1145/3297280.3297335}.
Unfortunately any solution to this problem will necessary encounter a phenomenon called \enquote{saturation} on large enough data streams \cite{10.1145/3297280.3297335}, and when it happens the algorithm performs no better than at random. 

This is problematic on two grounds: it makes the comparison of several algorithms difficult (since they all asymptotically behave in that fashion), and the unavoidable saturation ruins any particular design's merits. As such, it is more interesting to focus on wDDP rather than DDP.

\subsection{Contributions}
In this paper, we start from a naïve solution for the wDDP to then derive bounds for when it can be solved within $M$ bits of memory, up to a window size $w_\text{max}$, in constant time. We then introduce a generalization of the naïve solution, and study its error rate. We show that this construction, which we call Short Hash Filter (SHF), can push the value $w_\text{max}$ further while operating in constant time --- at the cost of some errors. %We also provide a different tradeoff, the Compact Short Hash Filter (CSHF), which uses fewer memory but operates in linear time.

Unfortunately, for $w > w_\text{max}$ the performance of SHF degrades very rapidly. We therefore turn our attention to existing data structures designed for the \enquote{non-windowed} setting. We show that some of them outperform dedicated data structures, including SHF, in the $w > w_\text{max}$ regime.

We then introduce the \enquote{queuing construction}, a black box transformation of non-windowed data structures into windowed ones, that improves their performance in the wDDP setting.

Finally, we provide an analysis of our queueing construction's resistance to adversarial streams.

\subsection{Related work}\label{sub:related}
The notion of sliding window was, as far as we know, first introduced in \cite{10.1145/1060745.1060753}.%; but several variations exist that are incomparable to one another (e.g. \cite{shtul2020agepartitioned}).
The wDDP formulation we rely on is due to \cite{Yoo10,She08}, which also introduce algorithms for solving the wDDP approximately.

The notion of using subfilters, as in the queuing construction, can be found in the A2 filter's design \cite{Yoo10} and a variation thereof can be found in \cite{shtul2020agepartitioned} but in a different DDP formulation. The A2 is built from two Bloom filters, a construction which we generalize and analyse generically in this paper. Similarly, the construction in \cite{shtul2020agepartitioned} only works with Bloom Filters.

%\section{Duplicate Detection and Filter Saturation}
\label{sec:dudefisa}
\section{Notations and basic definitions}
We consider an unbounded stream $E = (e_1, e_2, \dotsc, e_n, \dotsc)$ with elements belonging to an alphabet $\Gamma$.

%A filter is an algorithm, which has a finite amount of memory $M$ and, for each new element $e$, outputs $\DUPLICATE$ or $\UNSEEN$ whether it thinks $e$ is a duplicate or not.;

We usually consider the situations where the available memory is too small for perfect detection, i.e., $M \ll |\Gamma|$. Otherwise, if $M = |\Gamma|$ then the problem can be solved in constant time without errors \cite{10.1145/3297280.3297335}.

An element $e_j$ is a duplicate in $E$ over the sliding window $w$, and we note $e_i \wdup E$ if there exists $j-w \leq i < j$ such that $e_i = e_j$. Otherwise we note $e_i \notwdup E$, and we say $e_i$ is unseen over $w$.
A false positive over $w$ is an element $e\notwdup E$ which is classified as a duplicate, and a false negative is an element $e\wdup E$ which is classified as a not-duplicate.

For a filter, the probability of false positive ($\FP^w_i$) is the probability that after $i$ insertions, the \emph{unseen} element $e_i\notwdup E$ is a false positive over $w$. The false positive rate $\FPR^w_i$ is the number of false positives divided by the number of unseen elements in E\footnote{We observe that $\FPR^w_n = \frac{1}{n}\sum_{i=1}^n \FP^w_i$, and similarly for $\FNR^w_n$.}. We similarly define the false negative probability $\FN^w_i$, and the false negative rate $\FNR^w_i$.



\paragraph{Remark.} For benchmarking, we usually measure the error rate $ER = \FPR^w + \FNR^w$, as it allows a practical ranking of the solutions. An error rate of $0$ means a perfect filter, while a filter answering randomly has an error rate of $1$. A filter being always wrong has an error rate of $2$.


%\section{DDFs and the wDDP}
%A literature review collects the following DDF constructions: A2 filters \cite{Yoo10}, Stable Bloom Filters (SBF) \cite{Den06}, Quotient Hash Tables (QHT) \cite{10.1145/3297280.3297335}, Streaming Quotient Filters (SQF) \cite{Dut13}, Block-decaying Bloom Filters (b\_DBF) \cite{She08}, and a slight variation of Cuckoo Filters \cite{Fan14} suggested by \cite{10.1145/3297280.3297335}. The structure proposed in \cite{10.1145/1060745.1060753} is not desined for wDDP but a variant called `landmark` sliding window, which consists of a zero-resetting of the memory at some user-defined epochs.
%
%Of these, only the A2 and b\_DBF were designed explicitly for the wDDP. Others DDFs do not account for a finite-length sliding window, and therefore cannot be adjusted as a function of $w$. Another remarkable (but experimental) observation is that these DDFs' false positive rate does not decrease to 0 when the sliding window becomes small.


\section{Approximate solution and SHF}
%\subsection{Optimal wDDF}\label{sub:opt_solutions}
%
%Our goal is to minimise both the false positive and false negative rates of a DDF, given a fixed and limited amount of memory. Before going into details, we first explore the limits of the problem, i.e., when perfect or very performant solutions exist.
%
%\begin{theorem}
%	For $M \geq w (\log_2(w) + 2\log_2(|\Gamma|))$, the wDDP can be solved exactly (with no errors) in constant time.
%\end{theorem}

%\begin{proof}
%	We explicitly construct a DDF that performs the detection. Storing all $w$ elements in the sliding window takes $w\log_2(|\Gamma|)$ memory, using a FIFO queue $Q$; however 
%	lookup has a worst-time complexity of $O(w)$. 
%	
%	We therefore rely on an
%	ancillary data structure for the sake of quickly answering lookup questions.
%	Namely we use a dictionary $D$ whose keys are elements from $\Gamma$ and values are counters.
%	
%	When an element $e$ is inserted in the DDF, $e$ is stored and $D[e]$ is incremented (if the key $e$ did not exist in $D$, it is created first, and
%	$D[e]$ is set to $1$). In order to keep the number of stored elements to $w$, 
%	we discard the oldest element $e_\text{last}$ in $Q$. As we do so, we also decrement $D[e_\text{last}]$, and if $D[e_{last}] = 0$ the key is deleted from $D$. The whole insertion procedure is therefore performed in constant time.
%	
%	Lookup of an element $e^\star$ is simply done by looking whether the key $D[e^\star]$ exists, which is done in constant time.
%	
%	The size of the queue is $w\log_2 |\Gamma|$, the size of the dictionary is $w (\log_2 |\Gamma| + \log_2 w)$ (as the dictionary cannot have more than $w$ keys at the same time, a dictionary key occupies $\log_2 |\Gamma|$ bits and a counter cannot go over $w$, thus being less than $\log_2 w$ bits long). Thus a requirement of $w (\log_2(w) + 2\log_2(|\Gamma|))$ bits for this DDF to work.
%
%	Finally this filter does not make any mistake, as the dictionary $D$ keeps an exact account of how many times each element is present in the sliding window.
%\end{proof}

\subsection{Optimal and Approximate Optimal wDDF}
%The optimal filter described above requires that the size of $\Gamma$ is known in advance. The dependence on $\log_2 |\Gamma|$ can be dropped, at the cost of allowing errors.
\begin{restatable}{thm}{optwddf}\label{thm:opt_wddf}
	For $M \geq w (\log_2(w) + 2\log_2(|\Gamma|))$, the wDDP can be solved exactly (with no errors) in constant time.
\end{restatable}
	
\begin{proof}
	Due to page limit restrictions, all theorem proofs' are in Appendix~\ref{app:proofs}.
\end{proof}

However, this optimal filter requires that the size of $\Gamma$ is known in advance. The dependence on $\log_2 |\Gamma|$ can be dropped, at the cost of allowing errors.

\begin{restatable}{thm}{shf}\label{thm:SHF}
	Let $w \in \mathbb N$. Let $M \simeq 2w\log_2w$, then the wDDP can be solved with almost no error using $M$ bits of memory.
	
	More precisely, it is possible to create a filter of $M$ bits with an FN of $0$, an FP of $1 - (1-\frac1{w^2})^w \sim \frac 1w$, and a time complexity of $O(w)$.
	
	Using $M \simeq 5w\log_2 w$ bits of memory, a constant-time filter with the same error rate can be constructed.
\end{restatable}
Note that we only consider the probability of false positive after the filter has inserted at least $w$ elements, i.e., once the filter is full and has reached a stationary regime.


%\begin{proof}
%	Here again we explicitly construct the filters that attain the theorem's bounds.
%
%	Let $h$ be a hash function with codomain $\{0,1\}^{2 \log_2 w}$.
%The birthday theorem \cite{10.1007/3-540-45708-9_19} states that for a hash function $h$ over $a$ bits, one must on average collect $2^{a/2}$ input-output pairs before obtaining a collision. Therefore $2^{(2 \log_2 w) / 2} = w$ hash values $h(e_i)$ can be computed before having a $50\%$ probability of a collision (here, a collision is when two distinct elements of the stream $e_i, e_j$ with $i \neq j, e_i \neq e_j$ have the same hash, i.e. $h(e_i) = h(e_j)$). The 50\% threshold we impose on $h$ is arbitrary but nonetheless practical.
%
%Let $\mathcal F$ be the following DDF: the filter's state consists in a queue of $w$ hashes, and for each new element $e$, $\mathsf{Detect}(e)$ returns \DUPLICATE if $h(e)$ is present in the queue, \UNSEEN otherwise. $\mathsf{Insert}(e)$ appends $h(e)$ to the queue before popping the queue. 
%
%There is no false negative, and a false positive only happens if the new element to be inserted collides with at least one other element, which happens with probability $1 - (1 - \frac 1{2^{2\log_2w}})^{w} = 1 - (1-\frac1{w^2})^w$, hence an FN of $0$ and a FP of $1 - (1-\frac1{w^2})^w$.
%The queue stores $w$ hashes, and as such requires $w \cdot 2\log_2 w$ bits of memory.
%
%Note that this solution has a time complexity of $O(w)$. Using an additional dictionary, as in the previous proof, but with keys of size $2\log_2(w)$, we get a filter with an error rate of about $\frac 1w$ and constant time for insertion and lookup, using $w \cdot 2\log_2 w + w \cdot (2\log_2(w) + \log_2(w)) = 5w\log_2 w$ bits of memory.
%\end{proof}

When $\log_2|\Gamma| > 5 \log_2 w$ this DDF outperforms the naïve strategy\footnote{The naïve strategy consisting of storing the $w$ elements of the sliding window, requiring $w \log_2|\Gamma|$ bits of memory.}, both in terms of time and memory, at the cost of a minimal error. When $\log_2|\Gamma| > 2 \log_2 w$, it outperforms the exact solution described sooner in terms of memory.

%\section{Short Hash Filter}
\subsection{Short Hash Filter Algorithm}
The approximate filter we described uses hashes of size $2\log_2(w)$ for a given sliding window $w$. However, this hash size is arbitrary, and while it guarantees a very low error rate, it can be changed. More importantly, in some practical cases the maximal amount of available memory is fixed beforehand. Fixing the memory is also more practical for benchmarking data structures, as it gives the guarantee that all filters operate under the same conditions.

This gives us the Short Hash Filter (SHF), described in Algorithm~\ref{alg:SHF}. The implementation relies on a double-ended queue or a ring buffer, which allows pushing at beggining of a queue and popping at the end in constant time.


\begin{algorithm}
	\caption{SHF Setup, Lookup and Insert}\label{alg:SHF}
	
	\begin{algorithmic}[1]
	\Function{Setup}{$M, w$}
	\Comment $M$ is the available memory, $w$ the size of the sliding window
	\State $h \gets$ hash function of codomain size $\lfloor \frac M{2w} - \frac 12 \log_2 w \rfloor$
	\State $Q \gets \emptyset$ \Comment $Q$ is a queue of elements of size $h$
	\State $D \gets \emptyset$ \Comment $D$ is a dictionary $h \Rightarrow$  counter (of max value $w$)
	
%	\State\Return filter
	\EndFunction 
	\end{algorithmic}

	\begin{multicols}{2}
	\begin{algorithmic}[1]
	\item[]
	\item[]
	\Function{Lookup}{$e$}
	\If{$D[h(e)] > 0$}
	\State \Return \DUPLICATE
	\EndIf
	\State \Return \UNSEEN
	\EndFunction
	\item[]
	\item[]
\end{algorithmic}

\begin{algorithmic}[1]
	\Function{Insert}{$e$}
	\State $Q.\mathsf{Push\_Front}(h(e))$
	\State $D[h(e)]$++
	
	\If{$Q.\mathsf{length}() > w$}
	\State $h' \gets Q.\mathsf{Pop\_back}()$
	\State $D[h']$-{}-
	\If{$D[h'] = 0$}
	\State Erase key $D[h']$
	\EndIf
	\EndIf
	\EndFunction
\end{algorithmic}
	\end{multicols}
\end{algorithm}

%\subsection{Compact Short Hash Filter}
%Removing the dictionary from the SHF construction yields a more memory-efficient, but less time-efficient construction, which we dub \enquote{compact} short hash filter (CSHF). The CSHF performs in linear time in $w$, and is a simple queue, the only point is that instead of storing $e$, one stores $h(e)$, where $h$ is a hash function of codomain size $\lfloor \frac Mw \rfloor$.% and is described in Algorithm~\ref{alg:CSHF}.

%\begin{algorithm}[!h]
%	\caption{CSHF, Setup, Lookup and Insert}\label{alg:CSHF}
%	
%	\begin{algorithmic}[1]
%		\Function{Setup}{$\mathcal M, w$}
%		\Comment $M$ is the available memory, $w$ the size of the sliding window
%		\State $h \gets$ hash function of codomain size $\lfloor \frac Mw \rfloor$
%		\State $Q \gets \emptyset$ \Comment $Q$ is a queue of elements of size $h$
%		\State\Return filter
%		\EndFunction 
%		\item[]
%	\end{algorithmic}
%	
%	\begin{algorithmic}[1]
%		\Function{Lookup}{$e$}
%		\State \Return $h(e) \in Q$ 
%		\EndFunction
%		\item[]
%	\end{algorithmic}
%	
%	\begin{algorithmic}[1]
%		\Function{Insert}{$e$}
%		\State $Q.\mathsf{Push\_Front}(h(e))$
%		
%		\If{$Q.\mathsf{length}() > w$}
%			\State $h' \gets Q.\mathsf{Pop\_back}()$
%		\EndIf
%		\EndFunction
%	\end{algorithmic}
%\end{algorithm}

\paragraph{Error Rates.}
Let $w> 0$ be a window size and $M > 0$ the available memory.

%We write $\FN^w_\text{SHF}$ the probability of false negative of an SHF with these parameters. We similarly define $\FP^w_\text{SHF}$.%, $\FN^w_\text{CSHF}$, $\FP^w_\text{CSHF}$. 

\begin{restatable}{thm}{fprSHF}\label{thm:fprSHF}	
	$\FN_\text{SHF}^w  = 0$  and $\FP_\text{SHF}^w = 1 - \left(1 - \sqrt{w2^{-M/w}}\right)^w$
\end{restatable}

%\begin{proof}
%	This is an immediate adaptation of the proof from Theorem~\ref{thm:SHF}. An SHF has fingerprints of size $h = \frac M{2w} - \frac 12 \log_2 w$, while a CSHF has fingerprints of size $h' = \frac Mw$.
%\end{proof}

%\paragraph{Remark:} A CSHF of size $M$ has the same error rate than an SHF of size $2M + w\log_2 w$.
\paragraph{Saturation.}
SHF and have strictly increasing error rates, which reach a threshold of $1/2$ for some maximum window size $w_\text{max}$. Beyond this value, these filters saturate extremely quickly: in other words, most SHF will either have an error rate of $0$ or $1$.

An illustration of this phenomenon can be seen in Figure~\ref{fig:shorts}, 
which shows the error rates for SHF with $M=10^5$, against 
a uniformly random stream of $18$-bit elements ($|\Gamma| = 2^{18}$). The benchmark used a finite stream of length $10^6$.

\begin{figure}[t]
\makebox[\textwidth]{\makebox[1.05\textwidth]{%
\begin{minipage}{.5\textwidth}
	\centering
	\input{graphs/bench_shorts.tex}
	\caption{Error rates of SHFs and CSHFs for $M = 10^5$ bits, for varying window sizes $w$.}\label{fig:shorts}
\end{minipage}
\hfill
\begin{minipage}{.5\textwidth}
	\centering
	\begin{tikzpicture}
		\input{graphs/er_n_artificial}
	\end{tikzpicture}
	\caption{Error rate (times 100) of DDFs of 1Mb as a function of stream length. Hatched area represents over-optimal (impossible) values.}\label{fig:graph_n}
\end{minipage}
}}
\end{figure}

The value $w_\text{max}$ can be obtained by solving (numerically) for $\FP^{w_\text{max}} = 1/2$ for a given $M$. %We numerically solved the equation $\FP^w = 0.5$ for these two filters, for about 200 different values of $M$, uniformly distributed \emph{on a log scale} between $10^2$ and $10^6$. Results
% are given in Figure~\ref{fig:w_opt} and 
Experiments indicate an approximately linear relationship between $M$ and $w_\text{max}$: %for large values of $M$:
 %$w_\text{max}^\text{CSHF} = 0.0627 M + 443$ ($r^2 = 0.9981$) and
$w_\text{max}^\text{SHF} = 0.0233 M + 186$ ($r^2 = 0.9977$).

%\begin{figure}[]
%	\input{graphs/w_opt_shf.tex}
%	\caption{Value $w_{max}$ for which SHF and CSHF reach an error of 0.5 ($\pm 0.001$), for several values of $M$.}\label{fig:w_opt}
%\end{figure}

\section{Non-windowed DDFs in a wDDP setting}
\subsection{Lower Bound on the Saturation Resistance}
As said in the introduction, it has been proven \cite{10.1145/3297280.3297335} that all filters will reach saturation on the DDP setting. However, they sometimes prove to be efficient in some specific wDDP settings.
This bound is useful for several reasons, notably it provides an estimation of how close to optimality existing filters are.

\begin{restatable}{thm}{asymptoticSaturation}\label{thm:asymptoticSaturation}
	Let $E$ be a stream of $n$ elements uniformly selected from an alphabet of size $|\Gamma|$. For any DDF using $M$ bits of memory, the error probability $E_n = \FP_n + \FN_n$ satisfies
$
	E_n \geq 1 - \frac{1 - \left(1 - \frac{1}{|\Gamma|}\right)^{M}}{1 - \left(1 - \frac 1{|\Gamma|}\right)^n} 
$
	for any $n > M$.
\end{restatable}
In particular, the asymptotic error rate $E_\infty$ satisfies 
$
	E_\infty \geq \left(1 - \frac{1}{|\Gamma|}\right)^{M} \approx 1 - M/|\Gamma|.
$

%\begin{proof}
%	By definition, a perfect filter has the lowest possible error rate.
%	With $M$ bits of memory, a perfect filter can store at most $M$ elements in memory \cite[Theorem 2.1]{10.1145/3297280.3297335}. Up to reordering the stream, without loss of generality because it is random, we may assumethat the filter stores the $M$ last elements of the stream: any other strategy cannot yield a strictly lower error rate.
%	
%	If an element is already stored in the filter, then the optimal filter will necessarily answer \DUPLICATE. On the other hand, if the element is not in memory, a perfect filter can choose to answer randomly. Let $p$ be the probability that a filter answers \DUPLICATE when an element is not in memory. An optimal filter will lower the error rate of any filter using the same strategy with a different probability.
%	
%	An unseen element, by definition, will be unseen in the $M$ last elements of the stream, and hence will not be in the filter's memory, so the filter will return \UNSEEN with probability $1-p$. For this reason, this filter has an FP probability of $p$.
%	
%	On the other hand, $e^\star \dup E$ is classified as \UNSEEN if and only if it was not seen in the last $M$ elements of the stream, and the filter answers \UNSEEN. Let $D$ be the event \enquote{\emph{There is at least one duplicate in the stream}} and $C$ be the event \enquote{\emph{There is a duplicate of $e^\star$ in the $M$ previous elements of the stream}}. Then $e^\star$ triggers a false negative with probability
%	\begin{align*}
%		\FN_n &= (1 - \Pr[C | D])(1-p) =  \left(1 - \frac{\Pr[C \cap D]}{\Pr[D]}\right)(1-p)\\
%		& = \left(1 - \frac{\Pr[C]}{\Pr[D]}\right)(1-p) =  \left(1 - \frac{1 - \Pr[\bar C]}{1 - \Pr[\bar D]}\right)(1-p) \\
%		\FN_n &=  \left(1 - \frac{1 - \left(1 - \frac 1{|\Gamma|}\right)^M}{1 - \left(1 - \frac 1{|\Gamma|}\right)^n}\right)(1-p)
%	\end{align*}
%	Hence, the error probability of the filter is
%	\begin{align*}
%		E_n 
%		& = \FN_n + p
%		=  \left(1 - \frac{1 - \left(1 - \frac{1}{|\Gamma|}\right)^{M}}{1 - \left(1 - \frac 1{|\Gamma|}\right)^n}\right)(1-p) + p \\
%		& = 1 - \frac{1-\left(1 - \frac{1}{|\Gamma|}\right)^{M}}{1 - \left(1 - \frac 1{|\Gamma|}\right)^n}(1-p),
%	\end{align*}
%	which is minimized when $p = 0$. 
%\end{proof}

Note, as highlighted in the proof, that this bound is \emph{not tight}: better bounds may exist, the study of which we leave as an open question for future work.


\subsection{Saturation Resistance of DDFs}\label{sub:saturation}
We now evaluate the saturation rate for several DDFs, in the original DDP setting (without sliding window). Parameters are chosen to yield equivalent memory footprints and were taken from \cite{10.1145/3297280.3297335}, namely:
%
\begin{itemize}
	\item QHT \cite{10.1145/3297280.3297335}, 1 bucket per row, 3 bits per fingerprint.
	\item SQF \cite{Dut13}, 1 bucket per row, $r = 2$ and $r' = 1$
	\item Cuckoo Filter \cite{Fan14}, cells containing 1 element of 3 bits each
	\item Stable Bloom Filter (SBF) \cite{Den06}, 2 bits per cell, 2 hash functions, targeted FPR of 0.02
%	\item $A2$ Filter \cite{Yoo10}, targeted FPR of $0.1$ on the sliding window.
%	\item Block-Decaying Bloom Filter (b\_DBF) \cite{She08}, sliding window of 6000 elements.
\end{itemize}
%


These filters are run against a stream of uniformly sampled elements from an alphabet of $2^{26}$ elements. This results in around 8\% duplicates amongst the 150 000 000 elements in the longest stream used. %As a comparison, we also run the same benchmark against a stream obtained from crawling data, the same one as \cite{10.1145/3297280.3297335}, a real-world source which is highly non-uniform --- note that in this case, our lower bound on the error rate does not apply, owing to the stream being compressible. In that stream, around 10\% were duplicates amongst the 150 000 000 elements.
Results are plotted in Figure~\ref{fig:graph_n}.

The best results are given by the following filters, in order: QHT, SQF, Cuckoo and SBF. We also observe that QHT and SQF have error rates relatively close to the lower bound, hence suggesting that these filters are close to optimality, especially since the lower bound is not tight.


\subsection{Performance in wDDP}
We now consider the performance of the filters just discussed in the \emph{windowed} setting, for which they were \emph{not} designed. In particular, it is not possible to adjust their parameters as a function of $w$.

Remarkably, some of these filters still outperform dedicated windowed filters for some window sizes at least, as shown in Figure~\ref{fig:nwddf-in-wddp}. In this benchmark, we used the following filters:
\begin{itemize}
	\item block decaying Bloom Filter\footnote{Note that by design, a b\_DBF of $10^5$ bits cannot be built over a sliding window bigger than $6000$.} (b\_DBF) \cite{She08}, sliding window of size $w$
	\item A2 filter \cite{Yoo10}, changing subfilter every $w/2$ insertions
	\item QHT \cite{10.1145/1060745.1060753}, 1 bucket per row, $3$ bits per fingerprint
\end{itemize}

Nevertheless, we will now discuss the queuing construction, which allow us to build windowed filters from the DDP filters.  

\begin{figure}[t]
\makebox[\textwidth]{\makebox[1.25\textwidth]{%
	\begin{minipage}{.5\textwidth}
	\centering
	\input{graphs/compare_qht_bdbf_a2.tex}
	\caption{Error rates for QHT, b\_DBF, and A2. While A2 and b\_DBF were designed and adjusted to the wDDP, this is not the case of QHT. Still, QHT outperforms these filters for some values of $w$.}
	\label{fig:nwddf-in-wddp}
	\end{minipage}
	\hfill
	\begin{minipage}{.7\textwidth}
	\centering
	\input{fig/queuef.tex}
	\caption{Architecture of the queuing filter. The filter is composed of $L$ subfilters $\mathcal F$, each containing up to $c$ elements. Once the newest subfilter has inserted $c$ elements in its structure, the oldest one is expired. As such, it is dropped and a new one is created and put under population at the beginning of the queue. In this example, the sub-sliding window of $\mathcal F_1$ is $(e_{m-2}, e_{m-3}, e_{m-4})$.} \label{fig:scheme}
	\end{minipage}
}}
\end{figure}


\section{Queuing filters}\label{sec:queue}
We now describe the queuing construction, which produces a sliding window DDF from any DDF. We first give the description of the setup, before studying the theoretical error rates. 
A scheme describing our structure is detailed in Figure~\ref{fig:scheme}.

\subsection{The queuing construction}

\paragraph{Principle of operation.}
Let $\mathcal F$ be a DDF. Rather than allocating the whole memory to $\mathcal F$, we will create $L$ copies of $\mathcal F$, each using a fraction of the available memory. Each of these \emph{subfilters} as a limited timespan, and is allowed up to $c$ insertions. The subfilters are organised in a queue.

When inserting a new element in the queuing filter, it is inserted in the topmost subfilter of the queue. After $c$ insertions, a new empty filter is added to the queue, and the oldest subfilter is popped and erased.

As such, we can consider that each subfilter operates on a sub-sliding window of size $c$, which makes the overall construction a DDF operating over a sliding window of size $w = cL$.

\paragraph{Insertion and lookup.}
The filter returns \DUPLICATE if and only if at least one subfilter does. Insertion is a simple insertion in the topmost subfilter.

\paragraph{Queue update.}
After $c$ insertions, the last filter of the queue is dropped, and a new (empty) filter is appended in front of the queue.

\paragraph{Pseudocode.}
We give a brief pseudocode for the queuing filter's functions \textsf{Lookup} and \textsf{Insert}, as well as a \textsf{Setup} function for initialisation, in Algorithm~\ref{alg:queuing}. We introduced for simplicity a constructor $\mathcal F.\textsf{Setup}$ that takes as input an integer $M$ and outputs an initialized empty filter $\mathcal F$ of size at most $M$. Here \texttt{subfilters} is a FIFO that has a \texttt{pop} and \texttt{push\_first} operations, which respectevely removes the last element in the queue or inserts a new item in first position.\footnote{Two standard ways to implement this are a double-ended queue (deque) and a ring buffer.}   

\begin{algorithm}[]
	\caption{Queuing Filter Setup, Lookup and Insert}\label{alg:queuing}
	
	\begin{algorithmic}[1]
	\Function{Setup}{$\mathcal F, M, L, c$}
		\Comment $M$ is the available memory, $\mathcal F$ the subfilter structure, $L$ the number of subfilters and $c$ the number of insertions per subfilter
		\State subfilters $\gets \emptyset$
		\State counter $\gets 0$
		\State $m \gets \lfloor M/L \rfloor$
		\For{$i$ from $0$ to $L-1$}
			\State subfilters.push\_first$(\mathcal F.\mathsf{Setup}(m))$
		\EndFor
		\State \textbf{store} (subfilters, $L$, $m$, counter)
%		\State\Return filter
	\EndFunction 
	\end{algorithmic}

	\begin{multicols}{2}
	\begin{algorithmic}[1]
	\Function{Lookup}{$e$}
		\For{$i$ from $0$ to $L-1$}
			\If{subfilters[i]$.\mathsf{Lookup(e)}$}
				\State \Return $\DUPLICATE$
			\EndIf
		\EndFor
		\State \Return \UNSEEN
	\EndFunction
	\item[]
	\end{algorithmic}

	\begin{algorithmic}[1]
	\Function{Insert}{$e$}
		\State subfilters[0]$.\mathsf{Insert}(e)$
		\State counter $\gets$ counter + 1 
		\If{counter == $c$}
			\State subfilters.pop()
			\State subfilters.push\_first($\mathcal F.\textsf{Setup}(m)$)
		\EndIf
	\EndFunction
	\end{algorithmic}
	\end{multicols}
\end{algorithm}

\subsection{Error rate analysis}
The queuing filter's properties can be derived from the subfilters'. False positive and false negative rates are of particular interest. In this section we consider a queuing filter $\mathcal Q$ with $L$ subfilters of type $\mathcal F$ and 
capacity $c$ (which means that the last subfilter is dropped after $c$ insertions).

\paragraph{Remark.}
	\label{subsub:number_elements}
	By definition, after $c$ insertions the last subfilter is dropped.
Information-theoretically, this means that all the information related to the elements inserted in that subfilter has been lost, and there are $c$ such elements by design. 
Therefore, in the steady-state regime, the queuing filter holds information about at least $c(L-1)$  elements (immediately after deleting the last subfilter) and at most $cL$ elements (immediately before this deletion). 

As a result, if $w < cL$, the queuing filter can hold information about \emph{more than $w$ elements}.

\subsubsection{Probability of False Positive}

\begin{restatable}{thm}{pfpQueue}
	\label{thm:queue-pfp}
	 Let $\FP_{\mathcal Q, m}^w$ be the probability of false positive %(def. \ref{def:pfp-pfn})
	 of $\mathcal Q$ after $m > w$ insertions, over a sliding window of size $w = cL$, we have \\
	$$%\begin{equation}
		\label{eq:queue-pfp}
		\FP_{\mathcal Q, m}^w = 1 - \left(1 - \FP_{\mathcal F,c}\right)^{L-1} \left(1 - \FP_{\mathcal F, m \bmod c }\right)
	$$ %\end{equation}
	where $\bmod$ is the modulo operator and 
	 $\FP_{\mathcal F,m}$ is the probability of false positive of a subfilter $\mathcal F$ after $m$ insertions.
\end{restatable}

%\begin{proof}
%	Let $E = (e_1, \dotsc, e_m, \dotsc)$ be a stream and $e^\star \notwdup E$. 
%	
%	Therefore, $e^\star$ is a false positive if and only if at least one subquery $\mathcal F_i.\mathsf{Lookup(e^\star)}$ returns \DUPLICATE. Conversely, $e^\star$ is \emph{not} a false positive when all subqueries $\mathcal F_i.\mathsf{Lookup(e^\star)}$ return \UNSEEN, i.e., when $e^\star$ is not a false positive for each subfilter.
%	
%	Each subfilter has undergone $c$ insertions, safe for the first subfilter which has only undergone $m \bmod c$, we immediately get Eq.~(\ref{eq:queue-pfp}).
%\end{proof}

\paragraph{Remark.} In the case $w < cL$, as mentioned previously, there is a non-zero probability that $e^\star$ is in the last subfilter's memory, despite not belonging to the sliding window. 
	
Assuming a uniformly random input stream, and writing $\delta = cL - w$, the probability that $e^\star$ has occurred in $\{e_{m-cL}, \dotsc e_{m-w+1}\}$ is $1-\left(1-\frac1{|\Gamma|}\right)^\delta$. For large $|\Gamma|$ (as is expected to be the case in most applications), this probability is about $\frac{\delta}{|\Gamma|} \ll 1$. Hence, we can neglect the probability that $e^\star$ is present in the filter, and we consider the result of Theorem~\ref{thm:queue-pfp} to be a very good approximation even when $w < cL$.

\subsubsection{Probability of False Negative}\label{sub:fnr}
\begin{restatable}{thm}{pfnQueue}
	\label{thm:queue-pfn}
	Let $\FN_{\mathcal Q, m}^w$ be the probability of false negative of $\mathcal Q$ after $m > w$ insertions on a sliding window of size $w = cL$, we have
	$$%\begin{equation}
	\FN_{\mathcal Q, m}^w 
	=  u_c^{L-1} u_{m \bmod c}
	$$%\end{equation}
	where $\bmod$ is the modulo operator, and we have introduced the short-hand notation $u_\eta= p_{\eta}\FN_{\mathcal F,\eta} + \left(1-p_{\eta}\right)\left(1-\FP_{\mathcal F,\eta}\right)$ where 
	$\FN_{\mathcal F,\eta}$ (resp. $\FP_{\mathcal F, \eta}$) is the probability of false negative (resp. false positive) of the subfilter $\mathcal F$ after $\eta$ insertions, and
	$%\begin{equation*}
		p_\eta = \frac{1-\left(1-\frac 1{|\Gamma|}\right)^\eta}{1-\left(1-\frac 1{|\Gamma|}\right)^w} \approx \frac{\eta}{w}.
	$%\end{equation*}
\end{restatable}

%\begin{proof}
%	Let $E = \{e_1, \dotsc, e_m, \dotsc\}$ be a stream, let $w$ be a sliding window and let $e^\star \wdup E$. 
%	
%	Then $e^\star$ is a false negative if and only if all subfilters $\mathcal F_i$ answer $\mathcal F_i.\mathsf{Detect}(e^\star) = \UNSEEN$. There can be two cases:
%	\begin{itemize}
%		\item $e^\star$ is present in $\mathcal F_i$'s sub-sliding window;
%		\item $e^\star$ is not present in $\mathcal F_i$'s sub-sliding window.
%	\end{itemize}
%In the first case, $\mathcal F_i.\mathsf{Detect}(e^\star)$ returns \UNSEEN if and only if $e^\star$ is a false negative for $\mathcal F_i$. This happens with probability $\FN_{\mathcal F,c}$ by definition, except for $\mathcal F_0$, for which the probability is $\FN_{\mathcal F, m\bmod c}$.
%
%In the second case, $\mathcal F_i.\mathsf{Detect}(e^\star)$ returns \UNSEEN if and only if $e^\star$ is not a false positive for $\mathcal F_i$, which happens with probability $1-\FP_{\mathcal F,c}$, execpt for $\mathcal F_0$, for which the probability is $1-\FP_{\mathcal F, m\bmod c}$.
%
%Finally, each event is weighted by the probability $p_c$ that $e^\star$ is in $\mathcal F_i$'s sub-sliding window:
%\begin{align*}
%	p_c 
%	& = \Pr[\text{$e^\star$ is in }\mathcal F_i \text{ sub-sliding window | } e^\star \wdup E]\\
%	& = \frac{\Pr[\text{$e^\star$ is in }\mathcal F_i \text{ sub-sliding window } \cap e^\star \wdup E]}{\Pr[e^\star \wdup E]}\\
%	& = \frac{\Pr[\text{$e^\star$ is in }\mathcal F_i \text{ sub-sliding window}]}{\Pr[e^\star \wdup E]}\\
%%		\end{align*}\begin{align*}p_c
%	& = \frac{1 - \Pr[\text{$e^\star$ is not in }\mathcal F_i \text{ sub-sliding window }]}{1 - \Pr[e^\star \notwdup E]}\\
%	& = \frac{1 - \left(1 - \frac 1{|\Gamma|}\right)^c}{1 - \left(1-\frac{1}{|\Gamma|}\right)^w}
%\end{align*}
%This concludes the proof.
%\end{proof}
\paragraph{Remark.} As previously, the effect of $w < cL$ is negligible for all practical purposes and Theorem~\ref{thm:queue-pfn} is considered a good approximation in that regime. 

\subsection{FNR and FPR}
From the above expressions we can derive relatively compact explicit formulas for the queuing filter's FPR and FNR when $m = cn$ for $n$ a positive integer.
\begin{restatable}{thm}{fprQueue}
	Let $\FPR_{\mathcal Q, m}^w$ be the false positive rate of $\mathcal Q$ after $m=cn > w$ insertions on a sliding window of size $w = cL$, we have
	\begin{equation*}
	\FPR_{\mathcal Q, cn}^w = 1 -  \frac{(1 - \FP_{\mathcal F, c})^{L-1}}{c}\sum_{\ell = 0}^{c-1} (1-\FP_{\mathcal F, \ell}).
	\end{equation*}
\end{restatable}
%\begin{proof}
%
%\begin{align*}
%	\FPR_{\mathcal Q, cn}^w
%	& = \frac{1}{cn} \sum_{k=1}^{cn} \FP_{\mathcal Q, k}^w 
%	 = \frac{1}{cn} \sum_{k=1}^{n} \sum_{\ell = 0}^{c-1} \FP_{\mathcal Q, k + \ell}^w 
%	 = \frac1c \sum_{\ell = 0}^{c-1} \FP_{\mathcal Q, \ell}^w \\
%	& = \frac1c \sum_{\ell = 0}^{c-1}  1 - (1 - \FP_{\mathcal F, c})^{L-1}(1 - \FP_{\mathcal F}, \ell) \\
%	& = 1 - \frac1c(1 - \FP_{\mathcal F, c})^{L-1}\sum_{\ell = 0}^{c-1} (1-\FP_{\mathcal F, \ell})
%\end{align*}
%\end{proof}

\begin{restatable}{thm}{fnrQueue}
	Let $\FNR_{\mathcal Q, m}^w$ be the false negative rate of $\mathcal Q$ after $m=cn > w$ insertions on a sliding window of size $w = cL$, we have
	\begin{equation*}
	\FNR_{\mathcal Q, cn}^w = \frac{u_c^{L-1}}{c}  \sum_{\ell = 0}^{c-1}u_\ell.
	\end{equation*}
\end{restatable}

%\begin{proof}
%\begin{align*}
%	\FNR_{\mathcal Q, cn}^w 
%	& = \frac{1}{cn} \sum_{k=1}^{cn} \FN_{\mathcal Q, k}^w 
%	 = \frac{1}{cn} \sum_{k=1}^{n} \sum_{\ell = 0}^{c-1} \FN_{\mathcal Q, k + \ell}^w 
%	= \frac1c \sum_{\ell = 0}^{c-1} \FN_{\mathcal Q, \ell}^w \\
%	& = \frac1c \sum_{\ell = 0}^{c-1} u_c^{L-1} u_{\ell} 
%	 = \frac{u_c^{L-1}}{c}  \sum_{\ell = 0}^{c-1}u_\ell
%\end{align*}
%\end{proof}
As for the probabilities, the expressions derived above for the FNR and FNR are valid to first order in $(w - cL)/|\Gamma|$, i.e. they are good approximations even when $w \approx cL$. 

\subsection{Optimising queuing filters}
\label{sec:optimising}
Let us relax, temporarily, the a priori constraint that $w = cL$. The parameter $L$ determines how many subfilters appear in the queuing construction. Summing up the false positive and false negative rates, we have a total error rate 
$	\operatorname{ER}_{\mathcal Q, cn}^{w}
	= 1 - \alpha \beta^{L-1} + \alpha' \beta'^{L-1}
$,
where $\beta = 1 - \FP_{\mathcal F, c}$, $\beta' = u_c$, 
$\alpha = \frac1c \sum_{\ell = 0}^{c-1}1 - \FP_{\mathcal F, \ell}$ and $\alpha' = \frac1c \sum_{\ell = 0}^{c-1} u_\ell$ depend on $w$, $c$ and the choice of subfilter type $\mathcal F$.

Because $u_\eta = p_{\eta}\FN_{\mathcal F,\eta} + \left(1-p_{\eta}\right)\left(1-\FP_{\mathcal F,\eta}\right)$, differentiating with respect to $L$, knowing that $w = Lc$, and equating the derivative to $0$, one can find the optimal value for $L$ by solving for $x$, which has been obtained via Mathematica:
%\begin{equation*}

\begin{align*}
&-\alpha \beta^{-1+x} \log(\beta) 
+ \left(\beta + \FN_{\mathcal F, c} (-1+x)\right)^{-2+x} x^{-x} \left[\vphantom{\left(\FN^{\FN}\right)}\right. 
	-\alpha \beta + \FN_{\mathcal F, c} \left(-\beta (-2+x)+ \FN_{\mathcal F, c} (-1+x)\right) \\
&\quad	+ \left(\alpha+ \FN_{\mathcal F, c} (-1+x)\right)
\times\left(\beta + \FN_{\mathcal F, c} (-1+x)\right) \left(\log\left(\beta + \FN_{\mathcal F, c} (-1+x)\right)-\log(x)\right)
\left.\vphantom{\left(\FN^{\FN}\right)}\right] = 0
\end{align*}

If numerically solving the equation for individual cases is feasible, it seems unlikely that a closed-form formula exists.
%\end{equation*}

%Differentiating with respect to $L$ and equating to zero gives an optimum
%\begin{equation*}
%	L_{c, \mathcal F} = -\log((\alpha \beta' \log(\beta))/(\alpha'\beta \log(\beta')))/\log(\beta/\beta').
%\end{equation*} 
%Thus for a given $c$ and choice of subfilter $\mathcal F$ we get an optimal value of $L = L_{c, \mathcal F}$,
%and we set, \emph{a posteriori}, $w \gets cL$.
%
%If instead $w$ is a given value, solving $w = c L_{c, \mathcal F}$ analytically may be challenging.
%A practical solution is to interpolate between explicitly computed values $cL_{c, \mathcal F}$ to find the 
%closest match for the target $w$.
%
%\todo[À vérifier la suite je suis pas convaincu encore]
%\begin{theorem}
%	In first approximation, a low value of $L$ for constant value $cL$ leads to a higher false negative probability for the queuing filter.
%\end{theorem}
%
%\begin{proof}
%As a matter of fact, on average the queuing filter consists of $L-1$ subfilters with $c$ insertions, and one subfilter with $\frac c2$ insertions. As such, we can say that the queuing filter is a representation of the last $(c-\frac12) L$ last elements. 
%
%Let us consider $e^\star \wdup E$. If, in the sliding window, all duplicates only happened at least $(c-\frac12)L$ epochs ago (which happens with probability $\left(1-\frac1{|\Gamma|}\right)^{(c-\frac12)L}$), we know that no duplicates happened in any subfilter's sliding window. By using the same reasoning as Theorem~\ref{thm:queue-pfn}'s proof, we get a probability of false negative of around $\left[0 + \left(1-\frac1{|\Gamma|}\right)^{(c-\frac12)L}(1-\FP_{\mathcal F,c})\right]^L$. Given that $cL \approx w$ which is a constant, we get that the probability of false positive mostly varies, in this case, with $\left(1-\FP_{\mathcal F,c}\right)^L$. 
%
%Hence, the lower $L$ is, the higher the probability of false negative will be.
%
%The approximations made in this proof are backed by experimental results.
%\end{proof}


\subsection{Queuing filters from existing DDFs}
\label{sec:subfilter-select}
\label{sec:optimal_ddf}
Our queuing construction relies on a choice of subfilters. A first observation 
is that we may assume that all subfilters can be instances of a single 
DDF design (rather than a combination of different designs).

Indeed, a simple symmetry argument shows that a heterogenous selection of subfilters is always worse than a homogeneous one: the crux is that all subfilters play the same role in turn. Therefore we lose nothing by replacing atomically one subfilter by a more efficient one. Applying this to each subfilter we end up with a homogenous selection.

It remains to decide which subfilter construction to choose. The results of an experimental comparison of different DDFs (details about the benchmark are given in Section~\ref{sub:saturation}) are summarized in Figure~\ref{fig:graph_n}. It appears that the most efficient filter (in terms of saturation rate) is the QHT, from \cite{10.1145/3297280.3297335}.

%As noted in Section~\ref{sub:related}, A2 filters are a primitive form of a queuing filter (with $L=2$ and Bloom filters as subfilters) and thus were not included in this benchmark, as we focused on adapting filters designed for DDP to the sliding window DDP. This raises the question of whether recursive constructions (queuing filters of queuing filters) have particularly interesting properties, which we leave open for future work. 

%In the experiments we use QHT for the benchmarking of the queuing construction.

\section{Experiments and Benchmarks}\label{sec:bench}

This section provides details and additional information on the benchmarking experiments run to validate the above analysis. All code is accessible online and will be disclosed after peer review.

\paragraph{Benchmarking queuing filters.}
Applying the queuing construction to DDFs from the literature, we get new filters which are compared in the wDDP setting.

In Section~\ref{sec:optimal_ddf} we suggested the heuristic that the DDFs with the least saturation rate in the DDP would yield the best (error-wise) queuing filter for the wDDP. This heuristic is supported by results, summarized in Figure~\ref{tab:comparing_queuing}. For this benchmark we used the following parameters: uniform stream from an alphabet of size $|\Gamma| = 2^{18}$, memory size $M=100,000$ bits, sliding window of size $w = 10,000$, and we measure the error rate (sum of $\FNR^w$ and $\FPR^w$).

A very interesting observation is that $Lw$ approaches the size of the stream, there is a drop in the error. This is an artifact due to the finite size of our simulations; the stream should be considered infinite, and this drop disappears as the simulation is run for longer (see Appendix~\ref{app:finite}). This effect also alters the error rates for smaller window sizes, albeit much less, and we expect that filter designers care primarily about the small window regime. Nevertheless a complete understanding of this effect would be of theoretical interest, and we leave the study of this phenomenon for future work.


\begin{figure}[t]
\makebox[\textwidth]{\makebox[1.15\textwidth]{%
	\begin{minipage}{.5\textwidth}
		\centering
		\input{graphs/compare_queues.tex}
		\caption{Error rate (times 100) of queuing filters as a function of window size, $M=10^5$, $L=10$, $|\Gamma| = 2^{18}$, on a stream of size $10^7$.}\label{tab:comparing_queuing}
	\end{minipage}
	\hfill
	\begin{minipage}{.6\textwidth}
		\centering
		\input{graphs/bench_l.tex}
		\caption{Evolution of the error rate of a queueing QHT as a function of $L$, for several window sizes, with $M=10^5$, $|\Gamma| = 2^{18}$, on a stream of size $10^6$.}\label{fig:bench_l}
	\end{minipage}
}}
\end{figure}

%\begin{table}[]
%	\begin{tabular}{rccccc}
%			   & $w=1000$ & $w=5000$ & $w=10^4$ & $w=10^5$ & $w=10^6$ \\ \hline
%		QHT    & \textbf{9.84} 	  & \textbf{26.25}	 & \textbf{41.09}	 & \textbf{87.89}	  & 70.76      \\
%		Cuckoo & 84.99	  & 99.94	 & 99.95	 & 99.93	  & 99.80      \\
%		SQF    & 16.73 	  & 48.76	 & 69.25	 & 95.77 	  & \textbf{70.14}     \\
%		SBF    & 54.88 	  & 93.93	 & 97.33	 & 97.41	  & 71.17      \\
%	\end{tabular}
%	\caption{Error rate (times 100) of various queuing filters on various sliding window sizes, $M=100000$, $L=10$, $|\Gamma| = 2^{16}$. For each sliding window, the best performance is written in bold.}\label{tab:comparing_queuing}
%\end{table}

\paragraph{The number of subfilters}\label{sub:L_bench}
The number of subfilters $L$ is an important parameter in the queuing construction, as it affects the filter's error rate in a nontrivial way. An illustration of this dependence is shown in Figure~\ref{fig:bench_l} which plots the error rate of a queueing QQHTD on an uniform stream of alphabet size $\Gamma = 2^{16}$, with $10^5$ elements in the stream, on various sliding window sizes. 

We observe that the optimal value for $L$ does indeed depend on the desired sliding window. However, other experiments on alphabets of other sizes yield very similar results, hence validating the observation made in Section~\ref{sec:optimising} that the optimal number of subfilters does not depends on the alphabet, at least in first approximation.

\paragraph{Filters vs queued filters.}
Using the same stream as previously, we can build queued filters (with an optimal value $L$ for each considered sliding window) and compare their performances to that of non-modified filters. Results on the QHT and SQF are shown in Figure~\ref{fig:improvement}, results for the Cuckoo and SBF are shown in Appendix~\ref{app:improvement}.

\begin{figure}[t]
	\centering
	\input{graphs/improvement.tex}
	\caption{Comparing performances of QHT and SQF filters, in `vanilla' setting or when placed in our queueing structure.}\label{fig:improvement}
\end{figure}

We observe that queueing filters do not necessarily behave better than their 'vanilla' counterparts, especially on large sliding windows. This can be interpreted by the fact that the DDPs were optimised for infinite sliding windows, and as such operate better than their queueing equivalent on large sliding windows.

\section{Adversarial Resistance of Queueing Filters}
\label{sec:adversarial}

As DDFs have numerous security applications, we now discuss the queuing construction from an adversarial standpoint. We consider an adversarial game in which the attacker wants to trigger false positives or false negatives over the sliding window. One motivation for doing so is causing cache saturation or denial of service by forcing cache misses, triggering false alarms or crafting fradulent transactions without triggering fraud detection systems.

In order to create a realistic adversary model, we assume like in \cite{DBLP:journals/corr/abs-1709-08920} that the adversary does not have access to the internal memory representation of the filter. Nonetheless, after every insertion she knows whether the inserted element was detected as a duplicate or not. 

We first recall the definition of an adversarial game, adapted to our context.
\begin{definition}
	An adversary $\mathcal A$ feeds data to a sliding window DDF $\mathcal Q$, and for each inserted element, $\mathcal A$ knows whether $\mathcal Q$ answers $\DUPLICATE$ or $\UNSEEN$, but has not access to $\mathcal Q$'s internal state $\mathcal M$. The game has two distinct parts.
\begin{itemize}
	\item In the first part, $\mathcal A$ can feed up to $n$ elements to $\mathcal Q$ and learn $\mathcal Q$'s response for each insertion.
	\item In the second part, $\mathcal A$ sends a unique element $e^\star$.
\end{itemize} 
 $\mathcal A$ wins the $n$-false positive adversarial game (resp. $n$-false negative adversarial game) if and only if $e^\star$ is a false positive (resp. a false negative).
 
 \end{definition}
Variants of these games over a sliding window of size $w$ are immediate.
 
\subsubsection{False positive and false negative resistance}

\begin{definition}[Adversarial False Positive Resistance]
	We say that a DDF $\mathcal F$ is $(p, n)$-\emph{resistant to adversarial false positives} if no polynomial-time probabilistic (PPT) adversary $\mathcal A$ can win the $n-$false positive adversarial game with probability more than $p$.  
\end{definition}
Note that if $\mathcal F$ is $(p,n)$-resistant, then it is $(p, m)$-resistant for all $m < n$.

We define similarly the notion of being \emph{resistant to adversarial false negatives}. Finally, both definitions also make sense in a sliding window context.

%\paragraph{\textbf{Bound on false positive resistance}}

\begin{restatable}[Bound on false positive resistance]{thm}{fprRes}
	Let $\mathcal Q$ be a filter of $L$ subfilters $\mathcal F_i$, with $c$ insertions maximum per subfilter, let $w$ be a sliding window. 
	
	If $\mathcal F$ is $(p, c)$-resistant to adversarial false positive attacks and $cL \leq w$, then $\mathcal Q$ is $(1-(1-p)^L, w)$-resistant to adversarial false positive attacks on a sliding window of size $w$.
	
	If $cL > w$, the adversary has a probability of success of at least $1-(1-p)^L$.
\end{restatable}

%\begin{proof}
%	If $cL \leq w$, then information-theoretically the subfilters only have information on elements in the sliding window.
%	The probability of false positive for $\mathcal Q$ is $1 - (1 - \FP_{\mathcal F, c})^L$, which is strictly increasing with $\FP_{\mathcal F,c}$. Hence, the optimal solution is reached by to maximising the probability of false positive in each subfilter $\mathcal F_i$. By hypothesis the latter is bounded above by $p$ after $c$ insertions.
%	
%	On the other hand, if $cL > w$ then oldest filter holds information about elements that are not in the sliding window anymore. Hence, a strategy for the attacker trying to trigger a false positive on $e^\star$ could be to make it so these oldest elements are all equal to $e^\star$. Let $E$ be the optimal adversarial stream for triggering a false positive on the sliding window $w$ with the element $e^\star$, when $cL \leq w$. The adversary $\mathcal A$ can create a new stream $E' = e^\star | e^\star | \dotsc | E$ where $e^\star$ is prepended $cL - w$ times to $E$.
%	
%	After $w$ insertions, the last subfilter will answer $\DUPLICATE$ with probability at least $p$, hence giving a lower bound on $\mathcal A's$ probability of success. If, for some reason, the last subfilter answers $\DUPLICATE$ with probability less than $p$, then the same reasoning as for when $cL \leq w$ still applies, hence we get the correspondig lower bound (which is, in this case, an equality).
%\end{proof}
%%
%\paragraph{\textbf{Bounds on false negative resistance}}

\begin{restatable}[Bounds on false negative resistance]{thm}{fnrRes}
	Let $\mathcal Q$ be a filter of $L$ subfilters of kind $\mathcal F$, with $c$ insertions maximum per subfilter, and let $w$ be a sliding window. 
	
	If $\mathcal F$ is $(p, c)$-resistant to adversarial false negative attacks, then $\mathcal A$ can win the adversarial game on the sliding window $w$ with probability at least $p^L$.
	
	Furthermore, for $q$ the lower bound on the probability of false positive $\FP_{\mathcal F,c}$ for a given stream, if $w \leq (L-1)c$ then $\mathcal Q$ is $(\min(1 - q, p)^{L-1}p, w)$-resistant to false negative attacks on the sliding window $w$.
	On the other hand if $w > (L-1)c$ then $\mathcal Q$ is  $(\max(1 - q, p)^{L}, w)$-resistant to false negative attacks on the sliding window $w$.
\end{restatable}

%\begin{proof}
%	Let us first prove that a PPT adversary $\mathcal A$ can win the game with probability at least $p^L$.
%	For this, let us consider the adversarial game against the subfilter $\mathcal F$: after $c$ insertions from an aversarial stream $E_c$, $\mathcal A$ choses a duplicate $e^\star$ which will be a false negative with proability $p$.
%	Hence, if $\mathcal A$ crafts, for the filter $\mathcal Q$, the following adversarial stream $E' = E_c \mid E_c \mid \cdots \mid E_c$ consisting of $L$ concatenations of the stream $E_c$, then $e^\star$ is a false negative for $\mathcal Q$ if and only if it is a false negative for all subfilters $\mathcal F_i$, hence a probability of success for $\mathcal A$ of $p^L$.
%	
%	Now, Let us prove the case where $w\leq (L-1)c$. In this case, at any time, $\mathcal Q$ remembers all elements from inside the sliding window. As we have seen in the previous example, the probability of success of $\mathcal A$ is strictly increasing with the probability of each subfilter to answer $\UNSEEN$. The probability of a subfilter to answer $\UNSEEN$ is:
%	
%	\begin{itemize}
%		\item $\FN'_{\mathcal F,c}$ if $e^\star$ is in the subfilter's sub-sliding window;
%		\item $1 - \FP'_{\mathcal F, c}$ if $e^\star$ is not in the subfilter's sub-sliding window
%	\end{itemize}
%	where $\FN'$ and $\FP'$ are the probabilities of false negative and positives on the adversarial stream (which may be different from a random uniform stream).
%	
%	However, since $e^\star$ is a duplicate, it is in at least one subfilter's sub-sliding window. As such, the optimal strategy for $\mathcal A$ is to maximise the probability of all subfilters to answer $\UNSEEN$.  
%	Now, $\FN'_{\mathcal F,c}$ is bounded above by $p$ and $1 - \FP'_{\mathcal F, c}$ is bounded above by $1-q$, so the best strategy is where as many filters as possible answer $\UNSEEN$ with probability $\max(p, 1-q)$, knowing that at least one filter must contain $e^\star$ and as such its probability for returning $\UNSEEN$ is at most $p$, hence the result.
%	
%	Now, let us consider the case when $w > (L-1)c$. We have already introduce the element $e^\star$ in the last $w$ elements, and we want to insert it again. It is possible, for the adversary, to create the following stream $E = (e_1, e_2, \dotsc, e_{c-1}, e^\star, e_{c+1}, \dotsc, e_{Lc}, e_{Lc + 1})$, and to insert $e^\star$ afterwards.
%	
%	When $e_{Lc+1}$ is inserted, all elements $(e_1, \dotsc, e_{c-1}, e^\star)$ are dropped as the oldest subfilter is popped. Hence, in this context $e^\star$ is not in any subfilter anymore, so by adapting the previous analysis, $\mathcal A$ can get a false negative with probability at most $\max(1 - q, p)^{L}$.
%\end{proof}
%% Acknowledgements 
%\begin{acks} \end{acks}

%% Bibliography

