\input{preamble.tex}

\begin{document}

\title{Adapting Duplicate Filters to a Sliding Window Context}

%% Replace by \iffalse when submitting anonymously 
\iftrue 
	\author{Rémi Géraud-Stewart}
	\affiliation{%
	\institution{Département d'informatique de l'ENS, École normale supérieure, CNRS, PSL Research University}
	\city{Paris} \state{France}
	} \email{remi.geraud@ens.fr}

	\author{Marius Lombard-Platet}
	\affiliation{%
	\institution{Département d'informatique de l'ENS, École normale supérieure, CNRS, PSL Research University}
	\city{Paris} \country{France}
	}
	\affiliation{%
	\institution{Be-Studys}
	\city{Geneva} \country{Switzerland}
	} \email{marius.lombard-platet@ens.fr}

	\author{David Naccache}
	\affiliation{%
	\institution{Département d'informatique de l'ENS, École normale supérieure, CNRS, PSL Research University}
	\city{Paris} \country{France}
	} \email{david.naccache@ens.fr}
\fi 

%% Abstract
\begin{abstract}
	A duplicate filter is a data structure designed to efficiently detect repetitions (duplicates) in a stream. A well-known instance of such a data structure is the Bloom filter, which has been generalised in several ways.

	In this paper we introduce a generic framework that adapts duplicate filters to sliding windows, rather than on an infinite stream. Indeed, although the
	infinite stream setting is known to be ill-defined, many duplicate filters are only described in such a scenario. This enables a rigourous mathematical study of such filters.
\end{abstract}

%% CCS XML
\begin{CCSXML}
	% Get code at http://dl.acm.org/ccs.cfm.
	% Please copy and paste the code
\end{CCSXML}

%% Keywords
\keywords{
	% TODO
}

\maketitle

\section{Introduction}
\subsection{Motivation}

\paragraph{Duplicate detection problem.}
We consider the following problem (duplicate detection problem, DPP): given a stream $E_n = \{e_1, e_2, \dotsc, e_n\}$ and an item $e^\star$, find whether $e^\star \in E_n$. It is understood that the stream $E_n$ is updated at every time increment. An \emph{efficient} solution to this problem provides an answer with bounded error $\epsilon$, \todo[A verifier using polynomially many resources (time and memory) in $1/\epsilon$].

Instances of this problem abound in computer science, with applications in file system indexation, database queries, network load balancing, network management \cite{10.5555/647912.740658}, in credit card fraud \cite{DBLP:journals/corr/abs-1709-08920}, phone calls data mining \cite{10.1145/347090.347094}, etc. A discussion about algorithms on large data streams can be found in \cite{10.1145/776985.776986}. 
Even when the stream is bounded, i.e. $\lim_{n\to\infty}|E_n| < \infty$, it may be impractical to perform a complete lookup and approximate solutions are desirable. 

\paragraph{Fuzzy and approximate DPP}
A quite popular research topic on the subject of duplicate detection is \emph{fuzzy} detection \cite{10.5555/1287369.1287420,1410199,10.1109/ICDE.2011.5767865,10.1109/ICDE.2012.20,Monge97anefficient}. This is however out of the scope of our work, as we consider an element to be a duplicate if and only if the exact ame element has already appeared in the stream. \emph{Approximate} detection states that no attempt will be done to reach perfect accuracy, but rather to limit as much as possible the errors. One can prove \cite[Theorem 2.1]{10.1145/3297280.3297335} that perfect detection of duplicates over an alphabet of $U$ letters requires $U$ bits of memory, thus being impracticable in many cases.

As it turns out, approximate duplicate detection has many real-life use cases, and can sometimes play a critical role, for instance in cryptographic schemes where all security and secrecy fall apart as soon as a random nonce is used twice, such as the ElGamal \cite{10.1007/3-540-39568-7_2} or ECDSA signatures. Other uses include improvements over caches \cite{4484874}, duplicate clicks \cite{10.1145/1060745.1060753}, and others.

\todo[continuer].

\subsection{Contributions}

\subsection{Related Work}

\subsection{Organisation}


\section{Duplicate Detection and Filter Saturation}
\subsection{Notations and Initial Problem Statement}
Let us consider an alphabet $\Gamma$. A stream $E$ over $\Gamma$ is a (possibly infinite) set $E = \{e_1, e_2, \dotsc\}$, with each $e_i \in \Gamma$.

\begin{definition}[Duplicate and unseen element]
Let $E = \{e_1, e_2, \dotsc\}$ be a stream over $\Gamma$. Some element $e_j \in E$ is called a \emph{duplicate} if and only if there exists $i < j$ such that $e_i = e_j$. In that case we write $e_j \dup E$. Otherwise, $e_j$ is said to be \emph{unseen} and we write $e_j \notdup E$.
\end{definition}

\begin{definition}[Duplicate detection filter]
	A \emph{duplicate detection filter} (DDF) is a collection 
	$\mathcal F = (\mathcal S, \mathsf{Insert}, \mathsf{Detect})$ of a state\footnote{Here, $\mathcal M$ denotes all the memory states that can be reached by the filter.} $\mathcal S \in \mathcal M$ and two algorithms,
	\begin{itemize}
		\item $\mathsf{Detect}: \mathcal M \times \Gamma \to \{\DUPLICATE, \UNSEEN\}$;
		\item $\mathsf{Insert}: \mathcal M \times \Gamma \to \mathcal M$.
	\end{itemize}
	Informally, the $\mathsf{Detect}$ algorithm tentatively labels an element $e$ as duplicate or not, given the current state $\mathcal S$; whereas $\mathsf{Insert}$ takes as input the current state, an element $e$ to insert in the filter, and returns an updated memory state $\mathcal S'$. 
\end{definition}

We will usually consider the situations where the available memory is too small for perfect detection, i.e., $|\mathcal S| \ll |\Gamma|$.

\begin{definition}[False positive, false negative]
	Let $e \dup E$ (resp. $e \notdup E$) and $\mathcal F$ be a filter. We say that $e$ is a \emph{false positive} (resp. \emph{false negative}) when $\mathcal F.\mathsf{Detect}(e) = \DUPLICATE$ (resp. $\UNSEEN$).
\end{definition}

\begin{definition}[False positive rate, false negative rate]
	Let $E$ be a stream, $\mathcal F$ be a filter. The \emph{false positive rate} (resp. \emph{false negative rate}) of $\mathcal F$ over the first $i < n$ elements, denoted $\FPR_i$ (resp. $\FNR_i$), is defined as the ratio of false positives divided over the number of unseen elements in $\{e_1, \dotsc, e_i\}\subset E$ (resp. the ratio of false negative divided by the number of duplicate elements in that subset).
\end{definition}

However, it is more practical to work with another value, namely, the probability that after $m$ insertions, the element $e^*$ is a false positive (resp. false negative). 

\begin{definition}[Probability of false positive, of false negative]
	Let $E = \{e_1, \dotsc\}$ be a stream, $\mathcal F$ be a filter. The \emph{probability of false positive} (resp. \emph{probability of false negative}) of $\mathcal F$ after $i$ elements, denoted $\FP_i$ (resp. $\FN_i$), is defined as the proabability that $e_{i+1}$ is a false positive (resp. false negative).
\end{definition}

One can observe that $\FPR_n = \frac{1}{n}\sum_{i=1}^m \FP_i$, and similarly for $\FNR_n$.

\subsection{Filter Saturation and Sliding Windows}
Unfortunately, duplicate detection over an infinite stream has been identified as an ill-posed problem. As a matter of fact, as the number of bits of information of the stream grow to infinity, the filter can only remember an ever diminishing proportion of those bits, eventually having no advantage compared to a filter answering randomly.

In other terms, any DDF is asymptotically as good as a random guess:
	\begin{theorem}[\cite{10.1145/3297280.3297335}]\label{thm:sat_u}
	Let $\FNR_\infty$ and $\FPR_\infty$ be the asymptotic false negative and false positive rates of a filter of $M$ bits of memory (i.e. the FNR and FPR on a stream of size going to infinity).
	
	If $|\Gamma| \gg M$, then $\FNR_\infty + \FPR_\infty = 1$, which characterises random filters (i.e. filters answering randomly to any query).
\end{theorem}

One way out of this situation is to lower our expectations and work on a sliding window:

\begin{definition}[Sliding window DDP]
	Given a stream $E_n$ of fixed size $w$, with $E_n = \{e_{n-w+1}, \dotsc, e_n\}$ and an item $e^\star$, find whether $e^\star \in E_n$.
\end{definition} 

We therefore introduce new definitions suited to that setting:

\begin{definition}[Duplicate element, unseen element over a sliding window]
	Let $E = \{e_1, e_2, \dotsc\}$ be a stream over $\Gamma$, let $w\in \mathbb N$, an element $e_j \in E$ is called a \emph{duplicate} in $E$ over the sliding window of size $w$ if and only if there exists $j$ such that $j - w \leq i < j$  and $e_i = e_j$. In this case we write $e_j \wdup E$. Otherwise, $e_j$ is said to be \emph{unseen} and we write $e_j \notwdup E$.
\end{definition}

\begin{definition}[False positive, false negative over a sliding window]
	Let $w \in \mathbb N$, $e \notwdup E$ (resp. $e \wdup E$) and let $\mathcal F$ be a DDF. We say that $e$ is a \emph{false positive} (resp. \emph{false negative}) over $w$ if $\mathsf{Detect}(e) = \DUPLICATE$ (resp. $\UNSEEN$).
\end{definition}

\begin{definition}[False positive rate, false negative rate over a sliding window]
	Let $E$ be a stream, $\mathcal F$ be a DDF, $w \in \mathbb N$. The \emph{false positive} (resp. \emph{false negative}) rate of $\mathcal F$ over the first $i < n$ elements and the sliding window $w$, noted $\FPR^w_i$ (resp. $\FNR^w_i$), is defined as the number of false positives over $w$ divided by the number of unseen elements in $E$ over $w$ (resp. the number of false negative over $w$ divided by the number of duplicate elements over $w$).
\end{definition}


\subsection{Bounds on the Sliding Window DDP}

\begin{theorem}
	Let $w \in \mathbb N$. Let $M \simeq 2w\log_2w$, then the sliding window DDP can be solved with almost no error using $M$ bits of memory.
	
	More precisely, it is possible to create a filter of $M$ bits with an FNR of $0$, and an FPR of $1 - (1-\frac1{w^2})^w \sim \frac 1w$.
\end{theorem}

\begin{proof}
	Let $h$ be a hash function with codomain $\{0,1\}^{2 \log_2 w}$.
The birthday theorem, as summed up in \cite{10.1007/3-540-45708-9_19}, states that for a hash function $h$ over $a$ bits, one must on average collect $2^{a/2}$ input-output pairs before obtaining a collision. Therefore $2^{(2 \log_2 w) / 2} = w$ hash values $h(e_i)$ can be computed before having a $50\%$ probability of a collision (here, a collision is when two distinct elements of the stream $e_i, e_j$ with $i \neq j, e_i \neq e_j$ have the same hash, i.e. $h(e_i) = h(e_j)$). The 50\% threshold we impose on $h$ is arbitrary but nonetheless practical.

Let $\mathcal F$ be the following DDF: the filter's state consists in a queue of $w$ hashes, and for each new element $e$, $\mathsf{Detect}(e)$ returns \DUPLICATE if $h(e)$ is present in the queue, \UNSEEN otherwise. $\mathsf{Insert}(e)$ appends $h(e)$ to the queue before popping the list. 

There is no false negative, and a false positive only happens if the new element to be inserted collides with at least one other element, which happens with probability $1 - (1 - \frac 1{2^{2\log_2w}})^{w} = 1 - (1-\frac1{w^2})^w$, hence an FNR of $0$ and a FPR of $1 - (1-\frac1{w^2})^w$.
The queue stores $w$ hashes, and as such requires $w \cdot 2\log_2 w$ bits of memory.
\end{proof}

When $|\Gamma| > 2 \log_2 w$ (which is the case of most practical use cases) this DDF outperforms the naive strategy\footnote{The naïve strategy consisting of storing the $w$ elements of the sliding window, requiring $w |\Gamma|$ bits of memory.}, both in terms of time and memory.

Note that unlike the DDP, we do not necessarily encounter saturation for the sliding window DDP, which makes it possible for different DDF to have different performances in the asymptotic regime. 

Another remark is that when $M \approx w\log_2w$, it may be possible to solve the problem almost optimally in terms of error rate, the proposed solution remains very slow, requiring $O(w)$ computation time (although this complexity can be parallelized). Hence, it remains an open question of how to quickly detect duplicates in this context.

\subsection{DDP vs Sliding Window DDP}
The sliding window variant of DDP may seem to be a slight weakening of the original problem. Remarkably, it turns out that DDFs which perform well for the DDP do rather poorly for the sliding window DDP. A literature review collects the following DDF constructions: A2 filters \cite{Yoo10}, Stable Bloom Filters (SBF) \cite{Den06}, Quotient Hash Tables (QHT) \cite{10.1145/3297280.3297335}, Streaming Quotient Filters (SQF)\footnote{QHTs stem from a correction of SQFs, and as such SQFs are less efficient than QHT in every situation \cite{10.1145/3297280.3297335}. As such, only QHTs will be discussed.} \cite{Dut13}, Block-decaying Bloom Filters (b\_DBF) \cite{She08}, and a slight variation of Cuckoo Filters \cite{Fan14} suggested by \cite{10.1145/3297280.3297335}.

\todo[Regarder https://www2005.org/cdrom/docs/p12.pdf]

Of these, only the b\_DBF was defined in the context of a sliding window. The others do not account for a finite-length sliding window, and cannot be adjusted as a function of $w$. Another remarkable (but experimental) observation is that these DDFs' false positive rate does not decrease to 0 when the sliding window becomes small.

\todo[Expliquer ?]


\section{Queuing Filters for Sliding Window Adaptation}
In this section, we propose a way of adapting filters to a sliding window context. We first give the description of the setup, before studying the theoretical error rates.

\subsection{Queueing Filter}
Let $\mathcal F$ be a streaming filter, not designed to work on a sliding window. Our idea is, instead of spawning a filter $\mathcal F$ using as much memory as possible, to create $L$ small versions of $\mathcal F$, which all have a limited timespan and can store up to $c$ elements. These small filters are organised in a queue, in chronological order, the oldest filters being at the end of the queue. When the oldest filter reaches saturation, it is deleted, and a new small filter is instantiated, and placed at the beginning of the queue.

Since the goal is to remember all elements from a sliding window of size $w$, we have the relation $Lc \approx w$. The relation is only an approximation since it may be difficult, depending on the underlying subfilter, to ensure the equality. A scheme describing our structure is detailed in \Cref{fig:scheme}.

\begin{figure}
	\begin{tikzpicture}[scale=0.4]
	
	% F_0 under construction
	\draw[pattern=north west lines, pattern color=gray, draw=none] (1, 0) rectangle (2, 1);
	\draw (0, 0) rectangle (2, 1) node[midway] {$\mathcal F_0$};

	
	% Other subfilters
	\draw[pattern=north west lines, pattern color=gray] (3, 0) rectangle (5, 1) node[midway] {$\mathcal F_1$};
	\draw[pattern=north west lines, pattern color=gray] (6, 0) rectangle (8, 1) node[midway] {$\mathcal F_2$};
	\node at (9.5, 0.5) {...};
	\draw[pattern=north west lines, pattern color=gray] (11, 0) rectangle (13, 1) node[midway] {$\mathcal F_{L-1}$};
	
	% old subfilters
	\draw[dashed] (14, 0) rectangle (16, 1) node[midway] {$\mathcal F_{L}$};
	\draw[dashed] (17, 0) rectangle (19, 1) node[midway] {$\mathcal F_{L+1}$};
	
	% arrows
	\draw [<->,>=latex] (6, 1.5) -- (8, 1.5) node[above, midway] {$c$ elements};
	\draw [<->,>=latex] (0, -3) -- (13, -3) node[below, midway] {$Lc \approx w$ elements};
	\draw [<->,>=latex] (1, 3) -- (15, 3) node[above, midway] {Current sliding window (of size $w$)};
	
	
	%queueing filter
	\draw (-0.5, 2.5) rectangle (13.5, -2.5) node[anchor=south east] {Queuing filter};
	
	% legend
	\draw[draw=none, pattern=north west lines, pattern color=gray] (0.5, -5) rectangle (1, -5.5);
	\draw (0, -5) rectangle (1, -5.5) node[midway] {\tiny $\mathcal F$};
	\draw (1.25, -5.25) node[anchor=west] {\tiny Subfilter being populated};
	
	\draw[pattern=north west lines, pattern color=gray] (7, -5) rectangle (8, -5.5) node[midway] {\tiny $\mathcal F_i$};
	\draw (8.25, -5.25) node[anchor=west] {\tiny Populated active subfilter};
	
	\draw[dashed] (14, -5) rectangle (15, -5.5) node[midway] {\tiny $\mathcal F_j$};
	\draw (1 5.25, -5.25) node[anchor=west] {\tiny Expired subfilter};
	\end{tikzpicture}
	\caption{Architecture of the queuing filter. The filter is composed of $L$ subfilters $\mathcal F$, each containing up to $c$ elements. Once all subfilters are full with $c$ elements each, the oldest one is expired. As such, it is dropped and a new one is created and put under population at the beginning of the queue.}\label{fig:scheme}
\end{figure}

In the rest of this paper, we refer to the small filters constituting the queuing filter as \emph{subfilters}.

When the user wants to lookup for an element, they query all subfilters. If any subfilter answers with \DUPLICATE, the queueing filter answers \DUPLICATE. Otherwise, it answers \UNSEEN. Insertion is a simple insertion in the topmost subfilter.

After $c$ insertions (where $c$ is a filter parameter), the last filter of the queue is removed, and a new (empty) filter is appended in front of the queue. We give a brief pseudo-code of the queuing filter's functions \textsf{Lookup} and \textsf{Insert}, as well as a \textsf{Setup} function for initialisation, in \Cref{alg:queueing}.

For the sake of simplicity in the pseudocode, we assume that the subfilter $\mathcal F$ has a function \textsf{Setup} which takes as input the available memory $m$, and returns an initialized empty filter $\mathcal F$ of size at most $m$..

\begin{algorithm}[]
	\caption{Queueing Filter Setup, Lookup and Insert}\label{alg:queueing}
	
	\begin{algorithmic}[1]
	\Function{Setup}{$\mathcal F, M, L, c$}
		\Comment $M$ is the available memory, $\mathcal F$ the subfilter structure, $L$ the number of subfilters and $c$ the number of insertions per subfilter
		\State Queue\_storage $\gets$ empty queue
		\State Counter $\gets 0$
		\For{$i$ from $0$ to $L-1$}
			\State Queue\_storage[i] $\gets$ $\mathcal F.\mathsf{Setup}(\lfloor M/L \rfloor)$
		\EndFor
		Counter $\gets$ 0
		\State Store $c$, $M$, $L$, $\mathcal F$
		
		\State \Return filter
	\EndFunction 
	\item[]
	\end{algorithmic}

	\begin{algorithmic}[1]
	\Function{Lookup}{$e$}
		\For{$i$ from $0$ to $L-1$}
			\If{$\mathcal F_i.\mathsf{Lookup(e)}$}
				\State \Return $\DUPLICATE$
			\EndIf
		\EndFor
		\State \Return \UNSEEN
	\EndFunction
	\item[]
	\end{algorithmic}

	\begin{algorithmic}[1]
	\Function{Insert}{$e$}
		\State $\mathcal F_0.\mathsf{Insert}(e)$
		\State Counter++
		\If{Counter == $c$}
			\State Pop last element of Queue\_Storage
			\State Insert $\mathcal F$.\textsf{Setup}($\lfloor M/L \rfloor$) at the beginning of Queue\_Storage
		\EndIf
	\EndFunction
	\end{algorithmic}
\end{algorithm}

\subsection{Error Rate Analysis}
Depending on the underlying subfilter, the queueing filter will behave differently. However, its false positive and false negative probabilities can be derived from the underlying subfilter's false positive and false negative probabilities. 

\subsubsection{Number of Elements in a Queueing Filter}\label{subsub:number_elements}
Before deriving the error rates, it is important to analyse how many elements are in the filter. We know, by design, that no more than $cL$ elements can be present. However, after exactly $cL$ insertions, the last subfilter is deleted, to be replaced by an empty one at the beginning of the queue. Hence, after $cL$ insertions, only $c(L-1)$ elements are stored in the queueing filter.

Hence, the number of elements in the filter oscillate between $c(L-1)$ and $cL$. Furthermore, we have $cL \approx w$, which means that the number of elements in the filter can be higher than $w$. These facts must be kept in mind while deriving the error rates.

\subsubsection{Probability of False Positive}
\begin{theorem}
	Let $\mathcal Q$ be a queueing filter, consisting of $L$ underlying subfilters $\mathcal F$, each filled with up to $c$ elements. Let $\FP_{\mathcal F,m}$ be the probability of false positive of the subfilter $\mathcal F$ after $m$ insertions, let $\FP_{\mathcal Q, m}^w$ be the probability of false positive of $\mathcal Q$ after $m$ insertions on a sliding window of size $w$.
	
	We have $$\FP_{\mathcal Q, m}^w = 1 - (1 - \FP_{\mathcal F,c})^{L-1}(1 - \FP_{\mathcal F, m \% cL })$$ where \% is the modulo operator.
\end{theorem}

\begin{proof}
	Let $E = \{e_1, \dotsc, e_m, \dotsc\}$ be a stream, let $w$ be a sliding window and let $e^* \notwdup E$. We first take into account the remark in \Cref{subsub:number_elements} that the filter $\mathcal Q$ may contain more than $w$ elements, and hence potentially contain $e$ in memory, in the last subfilter of the queue. However, such event is quite rare, and can be neglected: let $\delta = cL - w$ the number of additional elements that can be stored in $\mathcal Q$. The probability that $e^*$ has occurred in $\{e_{m-cL}, \dotsc e_{m-w+1}\}$ is $1-\left(1-\frac1{|\Gamma|}\right)^\delta \approx \frac{\delta}{|\Gamma|} \approx 0$ since $\delta$ is likely to be small, while $|\Gamma|$ is too big for being stored in memory.
	
	Hence, we can neglect the probability that $e^*$ is present in the filter. Therefore, $e^*$ is a false positive if and only if at least one subquery $\mathcal F_i.\mathsf{Lookup(e^*)}$ return \DUPLICATE. Conversely, $e^*$ is not a false positive if and only if all subqueries $\mathcal F_i.\mathsf{Lookup(e^*)}$ return \UNSEEN. This can be rewritten as $e^*$ is not a false positive if and only if $e^*$ is not a false positive for each subfilter.
	
	Given that each subfilter stores $c$ elements, safe for the first subfilter which only stores $m \% cL$ elements, we get
	$$\FP_{\mathcal Q, m}^w = 1 - (1 - \FP_{\mathcal F, m \% cL })(1 - \FP_{\mathcal F,c})^{L-1}$$
\end{proof}

\subsubsection{False Negative Rate}
\begin{theorem}
	
\end{theorem}

\section{Application on Existing Filters}


\subsection{Optimal Error rate on a Subfilter}

\subsection{Filter Comparison}

\subsection{Application on QHT}

\section{Experiments and Benchmarks}

%% Acknowledgements 
%\begin{acks} \end{acks}

%% Bibliography
\bibliographystyle{ACM-Reference-Format}
\bibliography{qhtv2}

%% Appendix
%\appendix

\end{document}
