\input{preamble.tex}

\begin{document}

\title{Adapting Duplicate Filters to a Sliding Window Context}

%% Replace by \iffalse when submitting anonymously 
\iftrue 
	\author{Rémi Géraud-Stewart}
	\affiliation{%
	\institution{Département d'informatique de l'ENS, École normale supérieure, CNRS, PSL Research University}
	\city{Paris} \state{France}
	} \email{remi.geraud@ens.fr}

	\author{Marius Lombard-Platet}
	\affiliation{%
	\institution{Département d'informatique de l'ENS, École normale supérieure, CNRS, PSL Research University}
	\city{Paris} \country{France}
	}
	\affiliation{%
	\institution{Be-Studys}
	\city{Geneva} \country{Switzerland}
	} \email{marius.lombard-platet@ens.fr}

	\author{David Naccache}
	\affiliation{%
	\institution{Département d'informatique de l'ENS, École normale supérieure, CNRS, PSL Research University}
	\city{Paris} \country{France}
	} \email{david.naccache@ens.fr}
\fi 

%% Abstract
\begin{abstract}
	A duplicate filter is a data structure designed to efficiently detect repetitions (duplicates) in a stream. A well-known instance of such a data structure is the Bloom filter, which has been generalised in several ways.

	In this paper we introduce a generic framework that adapts duplicate filters to sliding windows, rather than on an infinite stream. Indeed, although the
	infinite stream setting is known to be ill-defined, many duplicate filters are only described in such a scenario. This enables a rigourous mathematical study of such filters.
\end{abstract}

%% CCS XML
\begin{CCSXML}
	% Get code at http://dl.acm.org/ccs.cfm.
	% Please copy and paste the code
\end{CCSXML}

%% Keywords
\keywords{
	% TODO
}

\maketitle

\section{Introduction}
\subsection{Motivation}

\paragraph{Duplicate detection problem.}
We consider the following problem (duplicate detection problem, DPP): given a stream $S_t = \{s_t, s_{t-1}, \dotsc\}$ and an item $s^\star$, find whether $s^\star \in S_t$. It is understood that the stream $S_t$ is updated at every time increment. An \emph{efficient} solution to this problem provides an answer with bounded error $\epsilon$, using polynomially many resources (time and memory) in $1/\epsilon$. 

Instances of this problem abound in computer science, with applications in file system indexation, database queries, network load balancing, network management \cite{10.5555/647912.740658}, in credit card fraud \cite{DBLP:journals/corr/abs-1709-08920}, phone calls data mining \cite{10.1145/347090.347094}, etc. A discussion about algorithms on large data streams can be found in \cite{10.1145/776985.776986}. 
Even when the stream is bounded, i.e. $\lim_{t\to\infty}|S_t| < \infty$, it may be impractical to perform a complete lookup and approximate solutions are desirable. 

\paragraph{Approximate and exact DPP.}
One way to relax the DPP is to allow \emph{approximate} duplicate detection \cite{10.5555/1287369.1287420,1410199,10.1109/ICDE.2011.5767865,10.1109/ICDE.2012.20,Monge97anefficient}. We instead focus on \emph{exact} duplicate detection, in which an element is considered a duplicate if and only if it has already appeared in the stream. One can prove \cite[Theorem 2.1]{10.1145/3297280.3297335} that perfect detection of duplicates over an alphabet of $U$ letters requires $U$ bits of memory. 

As it turns out, exact duplicate detection has many real-life use cases, and can sometimes play a critical role, for instance in cryptographic schemes where all security and secrecy fall apart as soon as a random nonce is used twice, such as the ElGamal \cite{10.1007/3-540-39568-7_2} or ECDSA signatures. Other uses include improvements over caches \cite{4484874}, duplicate clicks \cite{10.1145/1060745.1060753}, and others.

\todo[continuer].

\subsection{Contributions}

\subsection{Related Work}

\subsection{Organisation}


\section{Duplicate Detection and Filter Saturation}
\subsection{Notations and Initial Problem Statement}
Let us consider an alphabet $\Gamma$. A stream $E$ over $\Gamma$ is a (possibly infinite) collection $E = \{e_1, e_2, \dotsc\}$, with each $e_i \in \Gamma$.

\begin{definition}[Duplicate and unseen element]
Let $E = \{e_i\}$ be a stream over $\Gamma$. Some element $e_j \in E$ is called a \emph{duplicate} if and only if there exists $i < j$ such that $e_i = e_j$. In that case we write $e_j \in^2 E$. Otherwise, $e_j$ is said to be \emph{unseen} and we write $e_j \notin^2 E$.
\end{definition}

\begin{definition}[Duplicate detection filter]
	A \emph{duplicate detection filter} (DDF) is a collection of two algorithms 
	$\mathcal F = (\mathcal S, \mathsf{Insert}, \mathsf{Detect})$ of a state $\mathcal S \in \mathcal M$\footnote{Here, $\mathcal M$ denotes all the memory states that can be reached by the filter.} and two algorithms,
	\begin{itemize}
		\item $\mathsf{Detect}: \mathcal M \times \Gamma \to \{\DUPLICATE, \UNSEEN\}$;
		\item $\mathsf{Insert}: \mathcal M \times \Gamma \to \mathcal M$.
	\end{itemize}
	Informally, the $\mathsf{Detect}$ algorithm tentatively labels an element $e$ as duplicate or not, given the current state $\mathcal S$; whereas $\mathsf{Insert}$ takes as input the current state, an element $e$ to insert in the filter, and returns an updated memory state $\mathcal S'$. 
\end{definition}

We will usually consider the situations where the available memory is too small for perfect detection, i.e., $|\mathsf S| \ll |\Gamma|$.

\begin{definition}[False positive, false negative]
	Let $e \in^2 E$ (resp. $e \notin^2 E$) and $\mathcal F$ be a filter. We say that $e$ is a \emph{false positive} (resp. \emph{false negative}) when $\mathcal F.\mathsf{Detect}(e) = \DUPLICATE$ (resp. $\UNSEEN$).
\end{definition}

\begin{definition}[False positive rate, false negative rate]
	Let $E$ be a stream, $\mathcal F$ be a filter. The \emph{false positive rate} (resp. \emph{false negative rate}) of $\mathcal F$ over the first $i < n$ elements, denoted $\FPR_i$ (resp. $\FNR_i$), is defined as the ratio of false positives divided over the number of unseen elements in $\{e_1, \dotsc, e_i\}\subset E$ (resp. the ratio of false negative divided by the number of duplicate elements in that subset).
\end{definition}

\subsection{Filter Saturation and Sliding Windows}
Unfortunately, duplicate detection over an infinite stream has the following effect. Since a DDF can only store at most one element per bit \cite[Section 2.1]{10.1145/3297280.3297335}, a DDF of size $M$ can information-theoretically remember at most $M$ elements. Thus after $fM$ insertions (with $f \gg 1$), at most a small fraction $1/f \ll 1$ of the stream can be stored, we say that the DDF is \emph{saturated}. 

In other terms, any DDF is asymptotically as good as a random guess:
	\begin{theorem}[\cite{10.1145/3297280.3297335}]\label{thm:sat_u}
	Let $\FNR_\infty$ and $\FPR_\infty$ be the asymptotic false negative and false positive rates of a filter of $M$ bits of memory (i.e. the FNR and FPR on a stream of size going to infinity).
	
	If $|\Gamma| \gg M$, then $\FNR_\infty + \FPR_\infty = 1$, which characterises random filters (i.e. filters answering randomly to any query).
\end{theorem}
One way out of this situation is to lower our expectations and work on a sliding window:
\begin{definition}[Sliding window DDP]
	Given a stream of fixed size $S_t = \{s_t, \dotsc, s_{t-w}\}$ and an item $s^\star$, find whether $s^\star \in S_t$.
\end{definition} 
We therefore introduce new definitions suited to that setting:
\begin{definition}[Duplicate element, unseen element over a sliding window]
	Let $E = \{e_i\}$ be a stream over $\Gamma$, let $w\in \mathbb N$, an element $e_j \in E$ is called a \emph{duplicate} in $E$ over the sliding window of size $w$ if and only if there exists $j$ such that $j - w \leq i < j$  and $e_i = e_j$. In this case we write $e_j \in_w^2 E$. Otherwise, $e_j$ is said to be \emph{unseen} and we write $e_j \notin_w^2 E$.
\end{definition}
\begin{definition}[False positive, false negative over a sliding window]
	Let $w \in \mathbb N$, $e \notin_w^2 E$ (resp. $e \in_w^2 E$) and let $\mathcal F$ be a DDF. We say that $e$ is a \emph{false positive} (resp. \emph{false negative}) over $w$ if $\mathsf{Detect}(e) = \DUPLICATE$ (resp. $\UNSEEN$).
\end{definition}

\begin{definition}[False positive rate, false negative rate over a sliding window]
	Let $E$ be a stream, $\mathcal F$ be a DDF, $w \in \mathbb N$. The \emph{false positive} (resp. \emph{false negative}) rate of $\mathcal F$ over the first $i < n$ elements and the sliding window $w$, noted $\FPR^w_i$ (resp. $\FNR^w_i$), is defined as the number of false positives over $w$ divided by the number of unseen elements in $E$ over $w$ (resp. the number of false negative over $w$ divided by the number of duplicate elements over $w$).
\end{definition}

\subsection{Bounds on the Sliding Window DDP}
\todo[R.: je pense qu'on peut donner la probabilité exacte sans beaucoup plus d'effort]
\begin{theorem}
	Let $w \in \mathbb N$. Let $M \simeq 2w\log_2w$, then the sliding window DDP can be solved with almost no error using $M$ bits of memory.
\end{theorem}

\begin{proof}
	Let $h$ be a hash function with codomain $\{0,1\}^{2 \log_2 w}$.
The birthday theorem, as summed up in \cite{10.1007/3-540-45708-9_19}, states that for a hash function $h$ over $a$ bits, one must on average collect $2^{a/2}$ input-output pairs before obtaining a collision. Therefore $2^{2 \log_2 w / 2} = w$ values $h(e_i)$ can be computed before having a collision, i.e., two distinct elements of the stream $e_i, e_j$ with $i \neq j, e_i \neq e_j$ which have the same hash, i.e. $h(e_i) = h(e_j)$.

Let $\mathcal F$ be the following DDF: the filter's state consists in a queue of $w$ hashes, and for each new element $e$, $\mathsf{Detect}(e)$ returns \DUPLICATE if $h(e)$ is present in the queue, \UNSEEN otherwise. $\mathsf{Insert}(e)$ appends $h(e)$ to the queue before popping the list. 

There is no false negative, and a false positive only happens if two elements have the same hash, which does not happen often, hence a low FPR and a zero FNR.
The queue stores $w$ hashes, and as such requires $w \cdot 2\log_2 w$ bits of memory.
\end{proof}
When $|\Gamma| > 2 \log_2 w$ this DDF outperforms the naive strategy, both in terms of time and memory. Whether it is possible to bring the value of $M$ below $O(w \log_2 w)$ is an open problem. 

Note that unlike the DDP, we do not necessarily encounter saturation for the sliding window DDP, which makes it possible for different DDF to have different performances in the asymptotic regime. 

\subsection{DDP vs Sliding Window DDP}
The sliding window variant of DDP may seem to be a slight weakening of the original problem. Remarkably, it turns out that DDFs which perform well for the DDP do rather poorly for the sliding window DDP. A literature review collects the following DDF constructions: A2 filters \cite{Yoo10}, Stable Bloom Filters (SBF) \cite{Den06}, Quotient Hash Tables (QHT) \cite{10.1145/3297280.3297335}, Streaming Quotient Filters (SQF)\footnote{SQFs are a special case of QHTs \cite{10.1145/3297280.3297335}. As such, only QHT will be discussed.} \cite{Dut13}, Block-decaying Bloom Filters (b\_DBF) \cite{She08}, and a variation of Cuckoo Filters \cite{Fan14} suggested by \cite{10.1145/3297280.3297335}.

\todo[Regarder https://www2005.org/cdrom/docs/p12.pdf]

Of these, only the b\_DBF was defined in the context of a sliding window. The others do not account for a finite-length sliding window, and cannot be adjusted as a function of $w$. Another remarkable (but experimental) observation is that these DDFs' false positive rate does not decrease to 0 when the sliding window becomes small.

\todo[Expliquer ?]


\section{Queuing Filters for Sliding Window Adaptation}

\section{Application on QHT}

\section{Optimal Error rate on a Filter}

\section{Experiments and Benchmarks}

%% Acknowledgements 
%\begin{acks} \end{acks}

%% Bibliography
\bibliographystyle{ACM-Reference-Format}
\bibliography{qhtv2.bib}

%% Appendix
%\appendix

\end{document}
